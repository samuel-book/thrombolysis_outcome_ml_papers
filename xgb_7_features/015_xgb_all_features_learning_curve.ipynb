{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost to predict discharge disability: Do we have enough data?\n",
    "Learning curves: How much data do we need? Do we have enough?\n",
    "\n",
    "## Plain English summary\n",
    "One simple method to see whether we have enough data is to examine how accuracy increases with training set size. Does accuracy plateau before we hit the limit to how much data we have? In that case, getting more data will not help the model significantly. Is accuracy still increasing as we reach the limit to our data size? If so we would likely benefit from more data, if we can get it.\n",
    "\n",
    "We will wrap the model in a loop to increase the training set data size (taking a different random training/test split each time, and keeping the test set the same size). We will have an inner loop to perform 10 replicates at each sample size (to reduce the variation in our results)\n",
    "\n",
    "## Model and data\n",
    "Model: XGBoost classifier (multiclass classification) [from notebook 010]\\\n",
    "Target feature: Discharge disability\\\n",
    "Input features: All the relevant features in SSNAP\\\n",
    "Number of instances: different sizes of training data\\\n",
    "Kfold split: First kfold split\n",
    "\n",
    "We will go through the following steps:\n",
    "\n",
    "* Download and save pre-processed data\n",
    "* Split data into features (X) and label (y)\n",
    "* Split data into training and test sets (we will test on data that has not been used to fit the model)\n",
    "* Standardise data\n",
    "* Loop with increasing training set size:\n",
    "    * Loop through 10 replicates\n",
    "        * Fit a logistic regression model (from sklearn)\n",
    "        * Predict survival of the test set\n",
    "* Plot the relationship between training set size and accuracy\n",
    "\n",
    "## Aims\n",
    "Do we have enough data?\n",
    "\n",
    "## Observations\n",
    "It appears that we need all, if not more, data to obtain the best accuracy.\n",
    "\n",
    "## Further work\n",
    "Look at feature selection, see notebook 020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "A standard Anaconda install of Python (https://www.anaconda.com/distribution/) contains all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import machine learning methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the time duration to run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    '''Singleton object for storing paths to data and database.'''\n",
    "    image_save_path: str = './saved_images'\n",
    "    model_save_path: str = './saved_models'\n",
    "    data_save_path: str = './saved_data'\n",
    "    data_read_path: str = '../data_processing/output'\n",
    "    model_text: str = f'xgb_all_features_learning_curve'\n",
    "    notebook: str = '015_'\n",
    "\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(paths.data_read_path, '02_reformatted_data_ml.csv')\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features need to be removed from the dataset (those that are duplicates). Define a function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df, cols):\n",
    "    \"\"\"\n",
    "    For the dataframe, remove the columns 'cols' if they are present\n",
    "    \n",
    "    Args:\n",
    "        df [dataframe]: The feature values per patient\n",
    "        cols [list]: The features to remove if present\n",
    "\n",
    "    Return:\n",
    "        df [dataframe]: The feature values per patient without specified columns\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        if col in df.columns: df.drop([col],axis=1,inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_remove = ['id','stroke_team_id']\n",
    "data = drop_columns(data, cols_remove)\n",
    "feature_names = list(data)\n",
    "# number of dependant features\n",
    "n_features = len(feature_names) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = data['discharge_disability'].unique()\n",
    "class_names = np.sort(class_names)\n",
    "n_classes = len(class_names)\n",
    "print(f'There are {n_classes} target categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)\n",
    "\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are truing to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (survive or not) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y\n",
    "X = data.drop('discharge_disability', axis=1)\n",
    "y = data['discharge_disability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot the categorical features\n",
    "\n",
    "Convert some categorical features to one hot encoded features.\n",
    "\n",
    "Define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_to_one_hot(df, feature_name, prefix):\n",
    "    \"\"\"\n",
    "    Converts a categorical feature into a one hot encoded feature\n",
    "    \n",
    "    Args:\n",
    "        df [dataframe]: training or test dataset\n",
    "        feature_name [str]: feature to convert to one hot encoding\n",
    "        prefix [str]: string to use on new feature\n",
    "\n",
    "    Return:\n",
    "        df [dataframe]: One hot encoded representation of the feature\n",
    "    \"\"\"\n",
    "\n",
    "    # One hot encode a feature\n",
    "    df_feature = pd.get_dummies(\n",
    "        df[feature_name], prefix = prefix)\n",
    "    df = pd.concat([df, df_feature], axis=1)\n",
    "    df.drop(feature_name, axis=1, inplace=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up two lists for the one hot encoding. \n",
    "\n",
    "A list of the feature names that are categorical and to be converted using one hot encoding.\n",
    "A list of the prefixes to use for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_one_hot = [\"stroke_team\", \"weekday\"]\n",
    "list_prefix = [\"team\", \"weekday\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each feature in the list, fconvert to one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, prefix in zip(features_to_one_hot, list_prefix):\n",
    "    X = convert_feature_to_one_hot(X, feature, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature names with one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ohe = list(X)\n",
    "n_features_ohe = len(features_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {n_features} original features \"\n",
    "      f\"(before one-hot encoding)\")\n",
    "print(f\"There are {n_features_ohe} features (after one-hot encoding)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the maximum training set size we can use \n",
    "We will use 25% of data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.25\n",
    "data_rows = X.shape[0]\n",
    "max_training_size = int(data_rows * (1 - test_fraction))\n",
    "print('Max training size: {}'.format(max_training_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost models\n",
    "Loop through increasing training set sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list to collect results\n",
    "results_training_size = []\n",
    "results_roc_auc_ovr = []\n",
    "\n",
    "for train_size in range(1000, max_training_size, 1000):\n",
    "    replicate_roc_auc_ovr = []\n",
    "    for replicate in range(10):\n",
    "        y_train = np.array([])\n",
    "        # Keep spliting until get one of each category in the training set\n",
    "        while len(np.unique(y_train))!=n_classes:\n",
    "            # Split data into training and test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size = test_fraction)\n",
    "\n",
    "            # Reduce training set size (use np random choice for random index values)\n",
    "            selection_index = np.random.choice(\n",
    "                max_training_size, train_size, replace=False)\n",
    "            X_train = X_train.iloc[selection_index]\n",
    "            y_train = y_train.iloc[selection_index]\n",
    "\n",
    "        # Define model\n",
    "        model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Get target categories from model\n",
    "        classes = model.classes_\n",
    "\n",
    "        # Get predicted probabilities\n",
    "        y_probs = model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate ROC AUC for multiclass models, using One vs Rest\n",
    "        roc_auc_ovr = roc_auc_score(y_test, y_probs, labels = classes, \n",
    "                                    multi_class = 'ovr', average = 'macro')\n",
    "\n",
    "        # Record results\n",
    "        replicate_roc_auc_ovr.append(roc_auc_ovr)\n",
    "\n",
    "    results_roc_auc_ovr.append(np.mean(replicate_roc_auc_ovr))\n",
    "    results_training_size.append(train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curve\n",
    "\n",
    "We will plot the learning curve, including a moving average (the mean of 5 points). Moving averages can help show trends when data is noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate moving average (of last 5 points) with np.convolve\n",
    "moving_average = np.convolve(results_roc_auc_ovr, np.ones((5,))/5, mode='valid')\n",
    "# Include an offset to centre mean\n",
    "x_moving_average = results_training_size[2:-2]\n",
    "\n",
    "plt.scatter(results_training_size, results_roc_auc_ovr, \n",
    "         label='Accuracy')\n",
    "\n",
    "plt.plot(x_moving_average, moving_average,\n",
    "        label='Moving average',\n",
    "        color='orange',\n",
    "        linewidth=3)\n",
    "\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('Test set accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "filename = os.path.join(paths.image_save_path, \n",
    "                        (paths.notebook + paths.model_text + \n",
    "                         '_learning_curve.jpg'))\n",
    "plt.savefig(filename, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we need all, if not more, data to obtain the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "print(f'Time taken: {end_time - start_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('sam10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f85b883bff9a8a9f39576b94acbdf6672b3dc17c35647e7395f81e785740a4b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
